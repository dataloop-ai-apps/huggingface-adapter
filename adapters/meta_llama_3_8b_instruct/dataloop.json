{
    "name": "meta-llama3-8b-instruct-huggingface-app",
    "description": "Meta developed and released the Meta Llama 3 family of large language models (LLMs), a collection of pretrained and instruction tuned generative text models in 8 and 70B sizes. The Llama 3 instruction tuned models are optimized for dialogue use cases and outperform many of the available open source chat models on common industry benchmarks.",
    "attributes": {
        "Provider": "Meta",
        "Deployed By": "Dataloop",
        "License": "Other",
        "Category": "Model",
        "NLP": "Conversational",
        "Gen AI":"LLM",
        "Media Type": ["Text"]
    },
    "displayName": "Meta LLaMa3-8b-Instruct",
    "version": "0.1.62",
    "scope": "public",
    "codebase": {
        "type": "git",
        "gitUrl": "https://github.com/dataloop-ai-apps/huggingface-adapter.git",
        "gitTag": "0.1.62"
    },
    "components": {
        "computeConfigs": [
            {
                "name": "meta-llama-3-8b-instruct-huggingface-deploy",
                "secrets": [],
                "runtime": {
                    "podType": "gpu-t4-m",
                    "runnerImage": "dataloop_runner-gpu/huggingface-adapter:0.1.4",
                    "concurrency": 1,
                    "autoscaler": {
                        "type": "rabbitmq",
                        "minReplicas": 0,
                        "maxReplicas": 2,
                        "queueLength": 1000
                    },
                    "preemptible": false
                },
                "executionTimeout": 10800
            }
        ],
        "modules": [
            {
                "name": "meta-llama-3-8b-instruct-module",
                "entryPoint": "model_adapter.py",
                "className": "ModelAdapter",
                "computeConfig": "meta-llama-3-8b-instruct-huggingface-deploy",
                "initInputs": [
                    {
                        "type": "Model",
                        "name": "model_entity"
                    }
                ],
                "functions": [
                    {
                        "name": "predict_items",
                        "input": [
                            {
                                "type": "Item[]",
                                "name": "items",
                                "description": "The input images for prediction."
                            }
                        ],
                        "output": [
                            {
                                "type": "Item[]",
                                "name": "items",
                                "description": "The same input images for prediction."
                            },
                            {
                                "type": "Annotation[]",
                                "name": "annotations",
                                "description": "The predicted annotations."
                            }
                        ],
                        "displayName": "Predict Items",
                        "displayIcon": "",
                        "description": "The inference function of the model."
                    },
                    {
                        "name": "predict_dataset",
                        "input": [
                            {
                                "type": "Dataset",
                                "name": "dataset",
                                "description": "The input dataset of the items required for prediction."
                            },
                            {
                                "type": "Json",
                                "name": "filters",
                                "description": "The DQL in json format to get all the items required for prediction."
                            }
                        ],
                        "output": [],
                        "displayName": "Predict Dataset",
                        "displayIcon": "",
                        "description": "Inference function of the model on a dataset."
                    }
                ]
            }
        ],
        "models": [
            {
                "name": "meta-llama-3-8b-instruct-model",
                "moduleName": "meta-llama-3-8b-instruct-module",
                "scope": "project",
                "status": "pre-trained",
                "configuration": {
                    "weights_filename": "openllama.pt",
                    "model_path": "meta-llama/Meta-Llama-3-8B-Instruct",
                    "module_name": "adapters.meta_llama_3_8b_instruct.meta_llama_3_8b_instruct",
                    "device": "cuda:0",
                    "torch_dtype": "4bits",
                    "max_new_tokens": 20,
                    "temperature": 0.6,
                    "top_p": 0.9,
                    "hf_access_token": "",
                    "system_prompt": "You are an intelligent and helpful assistant that seeks to give precise and detailed information. Never mention who you are unless you are asked."
                },
                "tags": ["llm", "pretrained", "hugging-face"],
                "metadata": {},
                "description": "Meta developed and released the Meta Llama 3 family of large language models (LLMs), a collection of pretrained and instruction tuned generative text models in 8 and 70B sizes. The Llama 3 instruction tuned models are optimized for dialogue use cases and outperform many of the available open source chat models on common industry benchmarks."
            }
        ]
    }
}
