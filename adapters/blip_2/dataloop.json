{
    "name": "blip-2-huggingface-app",
    "description": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
    "attributes": {
      "Provider": "Hugging Face",
      "Deployed By": "Dataloop",
      "License": "BSD-3-Clause",
      "Category": "Model",
      "NLP": "Conversational",
      "Gen AI": "LMM",
      "Media Type": ["Text", "Image", "Multi Modal"]
    },
    "displayName": "BLIP 2",
    "version": "0.1.55",
    "scope": "public",
    "codebase": {
      "type": "git",
      "gitUrl": "https://github.com/dataloop-ai-apps/huggingface-adapter.git",
      "gitTag": "0.1.55"
    },
    "components": {
      "computeConfigs": [
        {
          "name": "blip-2-huggingface-deploy",
          "secrets": [],
          "runtime": {
            "podType": "regular-l",
            "runnerImage": "gcr.io/viewo-g/piper/agent/runner/apps/huggingface-adapter:0.1.45",
            "concurrency": 1,
            "autoscaler": {
              "minReplicas": 0,
              "maxReplicas": 2,
              "queueLength": 1000
            }
          }
        }
      ],
      "modules": [
        {
          "name": "blip-2-module",
          "entryPoint": "adapters/blip_2/blip_2.py",
          "className": "HuggingAdapter",
          "computeConfig": "blip-2-huggingface-deploy",
          "initInputs": [
            {
              "type": "Model",
              "name": "model_entity"
            }
          ],
          "functions": [
            {
              "name": "predict_items",
              "input": [
                {
                  "type": "Item[]",
                  "name": "items",
                  "description": "The input images for prediction."
                }
              ],
              "output": [
                {
                  "type": "Item[]",
                  "name": "items",
                  "description": "The same input images for prediction."
                },
                {
                  "type": "Annotation[]",
                  "name": "annotations",
                  "description": "The predicted annotations."
                }
              ],
              "displayName": "Predict Items",
              "displayIcon": "",
              "description": "The inference function of the model."
            },
            {
              "name": "predict_dataset",
              "input": [
                {
                  "type": "Dataset",
                  "name": "dataset",
                  "description": "The input dataset of the items required for prediction."
                },
                {
                  "type": "Json",
                  "name": "filters",
                  "description": "The DQL in json format to get all the items required for prediction."
                }
              ],
              "output": [],
              "displayName": "Predict Dataset",
              "displayIcon": "",
              "description": "Inference function of the model on a dataset."
            }
          ]
        }
      ],
      "models": [
        {
          "name": "blip-2-huggingface-model",
          "moduleName": "blip-2-module",
          "scope": "project",
          "status": "pre-trained",
          "configuration": {
            "model_name": "blip-2",
            "module_name": "adapters.blip_2.blip_2",
            "conditioning": false
          },
          "metadata": {},
          "description": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"
        }
      ]
    }
  }