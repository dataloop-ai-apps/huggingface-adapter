{
  "name": "smollm-huggingface-app",
  "description": "The SmolLM & SmolLM2 Huggingface Models are a family of compact language models available in three size: 135M, 360M, and 1.7B parameters. They are capable of solving a wide range of tasks while being lightweight enough to run on-device.",
  "version": "0.1.49",
  "scope": "project",
  "attributes": {
    "Provider": "HuggingFace",
    "Deployed By": "Dataloop",
    "License": "Apache 2.0",
    "Media Type": ["Text"],
    "Gen AI": "LLM",
    "Category": "Model",
    "NLP": "Conversational",
    "Hub": ["Dataloop"]
  },
  "components": {
    "computeConfigs": [
      {
        "name": "smollm-huggingface-deploy",
        "executionTimeout": 1200,
        "runtime": {
          "podType": "regular-m",
          "concurrency": 1,
          "runnerImage": "gcr.io/viewo-g/piper/agent/runner/apps/huggingface-adapter:0.1.4-SmolLM-3",
          "autoscaler": {
            "type": "rabbitmq",
            "minReplicas": 0,
            "maxReplicas": 2
          }
        }
      },
      {
        "name": "smollm-huggingface-train",
        "executionTimeout": 360000,
        "runtime": {
          "podType": "gpu-t4-m",
          "concurrency": 1,
          "runnerImage": "gcr.io/viewo-g/piper/agent/runner/apps/huggingface-adapter:0.1.4-SmolLM-2",
          "autoscaler": {
            "type": "rabbitmq",
            "minReplicas": 0,
            "maxReplicas": 1
          },
          "preemptible": false
        }
      }
    ],
    "modules": [
      {
        "name": "smollm-huggingface-module",
        "entryPoint": "adapters/smollm/model_adapter.py",
        "className": "ModelAdapter",
        "computeConfig": "smollm-huggingface-deploy",
        "initInputs": [
          {
            "type": "Model",
            "name": "model_entity"
          }
        ],
        "functions": [
          {
            "name": "predict_items",
            "input": [
              {
                "type": "Item[]",
                "name": "items",
                "description": "List of items to run inference on."
              }
            ],
            "output": [
              {
                "type": "Item[]",
                "name": "items",
                "description": "The same input items for prediction."
              },
              {
                "type": "Annotation[]",
                "name": "annotations",
                "description": "The predicted annotations."
              }
            ],
            "displayName": "Predict Items",
            "displayIcon": "",
            "description": "Run inference on a list of items with the model"
          },
          {
            "name": "predict_dataset",
            "input": [
              {
                "type": "Dataset",
                "name": "dataset",
                "description": "The input dataset of the items required for prediction."
              },
              {
                "type": "Json",
                "name": "filters",
                "description": "The DQL in json format to get all the items required for prediction."
              }
            ],
            "output": [],
            "displayName": "Predict Dataset",
            "displayIcon": "",
            "description": "Inference function of the model on a dataset."
          },
          {
            "name": "train_model",
            "computeConfig": "smollm-huggingface-train",
            "input": [
              {
                "type": "Model",
                "name": "model",
                "description": "Dataloop Model Entity"
              }
            ],
            "output": [
              {
                "type": "Model",
                "name": "model",
                "description": "Dataloop Model Entity"
              }
            ],
            "displayName": "Fine-tuned SmolLM Model",
            "displayIcon": "",
            "description": "Fine-tune the SmolLM model on a custom dataset using LoRA."
          }
        ]
      }
    ],
    "models": [
      {
        "name": "SmolLM2-135M-Instruct",
        "moduleName": "smollm-huggingface-module",
        "scope": "project",
        "status": "pre-trained",
        "outputType": "text",
        "configuration": {
          "module_name": "adapters.smollm.smollm_adapter",
          "model_path": "HuggingFaceTB/SmolLM2-135M-Instruct",
          "max_tokens": 1024,
          "temperature": 0.2,
          "top_p": 0.9,
          "stream": true,
          "system_prompt": "You are a helpful assistant.",
          "add_metadata": true,
          "max_length": 2048,
          "use_lora": true,
          "lora_r": 16,
          "lora_alpha": 32,
          "lora_dropout": 0.05,
          "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
        },
        "description": "SmolLM2-135M-Instruct Huggingface Model"
      },
      {
        "name": "SmolLM2-360M-Instruct",
        "moduleName": "smollm-huggingface-module",
        "scope": "project",
        "status": "pre-trained",
        "outputType": "text",
        "configuration": {
          "module_name": "adapters.smollm.smollm_adapter",
          "model_path": "HuggingFaceTB/SmolLM2-360M-Instruct",
          "max_tokens": 1024,
          "temperature": 0.2,
          "top_p": 0.9,
          "stream": true,
          "system_prompt": "You are a helpful assistant.",
          "add_metadata": true,
          "max_length": 2048,
          "use_lora": true,
          "lora_r": 16,
          "lora_alpha": 32,
          "lora_dropout": 0.05,
          "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
        },
        "description": "SmolLM2-360M-Instruct Huggingface Model"
      },
      {
        "name": "SmolLM2-1.7B-Instruct",
        "moduleName": "smollm-huggingface-module",
        "scope": "project",
        "status": "pre-trained",
        "outputType": "text",
        "configuration": {
          "module_name": "adapters.smollm.smollm_adapter",
          "model_path": "HuggingFaceTB/SmolLM2-1.7B-Instruct",
          "max_tokens": 1024,
          "temperature": 0.2,
          "top_p": 0.9,
          "stream": true,
          "system_prompt": "You are a helpful assistant.",
          "add_metadata": true,
          "max_length": 2048,
          "use_lora": true,
          "lora_r": 16,
          "lora_alpha": 32,
          "lora_dropout": 0.05,
          "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
        },
        "description": "SmolLM2-1.7B-Instruct Huggingface Model"
      },
      {
        "name": "SmolLM-135M-Instruct",
        "moduleName": "smollm-huggingface-module",
        "scope": "project",
        "status": "pre-trained",
        "outputType": "text",
        "configuration": {
          "module_name": "adapters.smollm.smollm_adapter",
          "model_path": "HuggingFaceTB/SmolLM-135M-Instruct",
          "max_tokens": 1024,
          "temperature": 0.2,
          "top_p": 0.9,
          "stream": true,
          "system_prompt": "You are a helpful assistant.",
          "add_metadata": true,
          "max_length": 2048,
          "use_lora": true,
          "lora_r": 16,
          "lora_alpha": 32,
          "lora_dropout": 0.05,
          "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
        },
        "description": "SmolLM-135M-Instruct Huggingface Model"
      },
      {
        "name": "SmolLM-360M-Instruct",
        "moduleName": "smollm-huggingface-module",
        "scope": "project",
        "status": "pre-trained",
        "outputType": "text",
        "configuration": {
          "module_name": "adapters.smollm.smollm_adapter",
          "model_path": "HuggingFaceTB/SmolLM-360M-Instruct",
          "max_tokens": 1024,
          "temperature": 0.2,
          "top_p": 0.9,
          "stream": true,
          "system_prompt": "You are a helpful assistant.",
          "add_metadata": true,
          "max_length": 2048,
          "use_lora": true,
          "lora_r": 16,
          "lora_alpha": 32,
          "lora_dropout": 0.05,
          "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
        },
        "description": "SmolLM-360M-Instruct Huggingface Model"
      },
      {
        "name": "SmolLM-1.7B-Instruct",
        "moduleName": "smollm-huggingface-module",
        "scope": "project", 
        "status": "pre-trained",
        "outputType": "text",
        "configuration": {
          "module_name": "adapters.smollm.smollm_adapter",
          "model_path": "HuggingFaceTB/SmolLM-1.7B-Instruct",
          "max_tokens": 1024,
          "temperature": 0.2,
          "top_p": 0.9,
          "stream": true,
          "system_prompt": "You are a helpful assistant.",
          "add_metadata": true,
          "max_length": 2048,
          "use_lora": true,
          "lora_r": 16,
          "lora_alpha": 32,
          "lora_dropout": 0.05,
          "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
        },
        "description": "SmolLM-1.7B-Instruct Huggingface Model"
      }
    ]
  }
}
